---
title: "DATA119 - Randomness and Simulation"
output: 
  learnr::tutorial:
    progressive: true
    css: css/custom-styles.css
runtime: shiny_prerendered
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(error = TRUE)
knitr::knit_engines$set(python = reticulate::eng_python)

library(learnr)
library(gradethis)
library(reticulate)

# Set the path to the existing Python environment
#reticulate::use_python("/opt/python/3.9.21/bin/python", required = TRUE)

# Optional: Install necessary Python packages if not already installed
# reticulate::py_install(c('numpy', 'pandas'))

custom_checker <- function(label, user_code, solution_code, envir_result, evaluate_result, last_value, stage, ...) {
  if (stage == "code_check") {
      if (user_code == solution_code){
          return(list(message = random_praise(), correct = TRUE))
      }
    return(list(message = random_encouragement(), correct = FALSE))
  }
}

gradethis_setup()
tutorial_options(exercise.completion = FALSE, exercise.checker = custom_checker)
```

```{r header, echo = FALSE}
library(htmltools)

tags$div(
  class = "topContainer",
  tags$div(
    class = "logoAndTitle",
    tags$img(
      src = "./images/dsi_logo.png",
      alt = "DSI Logo",
      class = "topLogo"
    ),
    tags$h1("Randomness and Simulation", class = "pageTitle")
  )
)
```

## Goals

The goals of this lab are:

* To learn how to use `np.random.choice` to select random values in python
* To practice using simulation to estimate probabilities
* To practice using simulations to improve decision making

## Randomness {data-progressive=FALSE}

Randomness plays a key role in much of data science. In fact, the probabilistic assumptions that underpin many of the tests and models you'll learn about in this class rely upon our ability as data scientists to inject randomness into our work. 

For instance, imagine if we were trying to estimate the average length of the grass on the quad (hopefully you never have to do this but imagine you did). To get a perfect answer (the population parameter) you could measure every piece of grass but it would be much simpler to take an average from a representative sample (the sample statistic). In order to take a good sample you might randomly choose 100 pieces from around the quad to measure and the randomness would be used to ensure it was likely representative. This is just one toy example of why randomness is important.

Beyond the above example though randomness plays a large role throughout data science from impacting our ability to measure the significance and variability of results to ensuring that we're fair and as unbiased as possible in our data collection processes.

### Overview  

In the remainder of the lab we'll start by introducing `np.random.choice` and `df.sample` which are two key ways in which we invoke randomness in python though there are many more. Next we'll get some practice using the power of randomness for estimating probabilities. Finally, we'll use randomness to simulate the results of a hypothetical line up in baseball to see how simulation could be used in practice.

### Setup {data-progressive=FALSE}
Before continuing we've done the imports for you here of `numpy` and `pandas`
```{python setup_py, exercise=TRUE, message = FALSE, echo=TRUE, exercise.eval=TRUE, context='setup'}
# data manipulation
import numpy as np
import pandas as pd
np.random.seed(42)
```

## Introduction to `np.random.choice`

The `numpy` library in python has a module called `random` which can be used to (pseudo) generate random numbers or samples. Within the [random module](https://numpy.org/doc/stable/reference/random/generator.html) it has many different ways to sample randomly but in this lab we'll focus on `np.random.choice`.

`np.random.choice(a, size=None, replace=True, p=None, **args)` randomly samples **size** elements from **a** or from the range **(0, a]** if a is an int. It samples with replacement when **replace** is True and the **p** argument can be used for probabilistic samples. 

To get you started thinking about the behavior of `np.random.choice` we have a couple questions for you. If you're uncertain I'd recommend just trying `np.random.choice` with different arguments in the cell below to get a feel for what it's doing.

```{python random-practice, include=TRUE, exercise = TRUE, message = FALSE, exercise.setup="setup_py"}
```


```{r q1, echo=FALSE}
question("1. What are possible samples from executing the code `np.random.choice(5, 2)`?",
         answer("`Error`", message = "The first argument can also be an interger"),
         answer("`3`", message = "The sample size is two so there will always be at least two numbers outputted"),
         answer("`np.array([1, 6])`", message="6 is outside the range of possible answers!"),
         answer("`np.array([2, 3])`", correct=TRUE),
        allow_retry = TRUE,
        post_message = "Congratulations! You have found the 1st secret word: RANDOM",
  random_answer_order = TRUE)
```

When using `np.random.choice` there may often be multiple ways to achieve the same goal. Which approach is right is generally left up to you; however, throughout this lab we might ask you to do something a certain way to gain experience.

```{r q2, echo=FALSE}
question("2. Which of the following code chunks when executed would simulate flipping two random fair coins and returning the number of heads? Select all that apply.",
         answer("`np.sum(np.random.choice(['H', 'T'], size=2)=='H')`", correct=TRUE),
         answer("`np.random.choice(['H', 'T'], size=1) + np.random.choice(['H', 'T'], size=1)`",message="While the idea is good we need to convert the result of the sample to a boolean in order to get the sum of the number of heads", correct=FALSE),
         answer("`np.sum(np.random.choice(['H', 'T'], size=2, replace=False)=='H')`", message="This would always give exactly 1 head!", correct=FALSE),
         answer("`np.sum(np.random.choice([0, 1], size=2))`", correct=TRUE),
         answer("`np.sum(np.random.choice([0, 1, 0, 1], size=2))`", correct=TRUE),
        allow_retry = TRUE,
        post_message = "Congratulations! You have found the 2nd secret word: OPTIONS",
  random_answer_order = TRUE)
```

```{r q2_hint, context="server"}
q2_correct_poll <- reactivePoll(500, session,
  checkFunc = function() get_tutorial_state()$q2$correct,
  valueFunc = function() get_tutorial_state()$q2$correct
)

q2_hint_visible <- reactiveVal(FALSE)
output$q2_plot_output <- renderUI({
  print(get_tutorial_state())
  if (isTRUE(q2_correct_poll())) {
    tagList(
      p("Discuss with a partner or on edStem about at least one of the following prompts."),
      actionButton("q2_show_hint_btn", "ðŸ’¡ Show discussion"),
      tags$div(
        id = "q2_hint_box",
        class="discussionbox",
        style = paste(
          if (!q2_hint_visible()) "display:none;" else "",
          "margin-top:.6px; border:1px solid #ddd; padding:.20px; border-radius:.5px;"
        ),
        tags$div(
        class = "center",
        tags$strong("Discuss with a neighbor (or on Ed):")
        ),
        tags$ol(
        tags$li("Why do we need to convert the letter 'H' to a boolean before summing the result? Why does summing booleans work for counting the number of heads?"),
         tags$li("One approach sampled from a list of two numbers [0, 1] and the other from a list of four numbers [0, 1, 0, 1]. Why are these two approaches essentially equivalent?"),
         tags$li("What are the implications from sampling the numbers 0 and 1 vs. 'H' and 'T' or another option like 'Heads' and 'Tails'? When might we prefer one approach to another?")
     )
    )
    )
  } else {
    tagList(
      p("Answer Question 2 correctly to reveal a discussion on approaches to using `np.random.choice`")
    )
  }
})

observeEvent(input$q2_show_hint_btn, {
  shinyjs::toggle(id = "q2_hint_box", anim = TRUE, time = 0.2)
  q2_hint_visible(!q2_hint_visible())
  updateActionButton(
    session, "q2_show_hint_btn",
    label = if (q2_hint_visible()) "ðŸ™ˆ Hide discussion" else "ðŸ’¡ Show discussion"
  )
})
```

```{r q2_conditional, echo=FALSE, eval=TRUE, message = FALSE, warning = FALSE}
uiOutput("q2_plot_output")
```


```{r q3, echo=FALSE}
question("3. True or False: The following block of code will generate a 12 numbers between 0 and 10. `np.random.choice(10, size=12, replace=False)`",
         answer("False", correct=TRUE),
         answer("True",message="If we're sampling without replacement our sample space must be larger than our sample size otherwise our code will error!", correct=FALSE),
        allow_retry = TRUE,
        post_message = "Great Job!",
  random_answer_order = TRUE)
```



Now that you've given some thought to how `np.random.choice` works here are some more examples and exercises to practice with it.

As mentioned above we can use the **p** argument when we want to sample probabilistically rather than every possible item in the sample having the same probability (a uniform sample). Here is one example of sampling a weighted coin.

```{python weighted-coin, exercise=TRUE, setup='setup_py'}
np.random.choice(['Heads', 'Tails'],size=5, p=[0.25, 0.75])
```

4. Use `np.random.choice` to randomly roll a die 6 times. The die should have even weight given to rolling a 1, 2, 3, or 4, and 25% chance each of rolling a 5 or 6. Use only 1 line.
```{python unfair-die, include=TRUE, exercise = TRUE, message = FALSE, exercise.setup="setup_py"}

```

```{python unfair-die-solution, message = FALSE, warning = FALSE, echo = FALSE}
np.random.choice([1, 2, 3, 4, 5, 6], size=6, p=[0.125, 0.125, 0.125, 0.125, 0.25, 0.25])
```
```{python unfair-die-hint-1,  message = FALSE, warning = FALSE, echo = FALSE}
Make sure that all the probabilities in the list given to p sum to 1. And there should be 1 probability for each number on the die.
```

```{python unfair-die-hint-2,  message = FALSE, warning = FALSE, echo = FALSE}
Remember we don't want to roll a zero so we have to pass in the entire list of numbers. If you're using np.arange that would also work but to pass the test just give it as a list.
```

```{r unfair-die-code-check, message = TRUE, warning = FALSE}
grade_this_code(
  correct = "That's an unfair die!",
)
```

## Simulation

The ability to draw random samples may be enough for some use cases. However, sometimes we may want to keep track of many random samples. For instance, if we wanted to know the probability of getting between 45 and 55 heads out of 100 tosses of a fair coin we could do the calculation; however, we could also use python to toss 100 coins 1000 times each and count the number out of 1000 where of the 100 flips in a single round 45 to 55 ended up heads. Whatever that proportion ends up being would be the estimated probability and as long as we do enough simulations should be a very accurate approximation of the true probability. 

Before we can actually conduct estimate the probability of getting between 45 and 55 heads out of 100 using simulation lets break down what are the necessary components. First, if we want to know the probability of getting between 45 and 55 heads out of 100 flips we need a way to simulate 100 flips. Second, we need a way to check if between 45 and 55 of those flips were heads. Third, we need a way to keep track of each round of simulation. And finally, we need a way to repeat our simulation of 100 flips enough times for our estimate to be accurate. Once we've done all of the above we'll able to easily summarize our answer.

In the following questions we'll build up all the code we need to run this simulation. 

### One Simulation: Flip the Coins

5. Write code to simulate 100 flips of a fair coin using the `coin` defined for you.

```{python q5, exercise = TRUE, message = FALSE, exercise.setup="setup_py"}
coin = ['Heads', 'Tails']
# your code goes here
```


```{python q5-solution, message = FALSE, warning = FALSE, echo = FALSE}
coin = ['Heads', 'Tails']
np.random.choice(coin, size=100)
```

```{r q5-code-check, message = TRUE, warning = FALSE}
grade_this_code(
  correct = "That's an unfair die!",
)
```

### One Simulation: Count the Heads

Once we have 100 randomly generated coin flips we need a way to keep track of whether or not that round resulted in a "success" of 45-55 Heads or not. 

6. Fill in the following code to get the result of a single round.

```{python q6, exercise = TRUE, message = FALSE, exercise.setup="setup_py"}
coin = ['Heads', 'Tails']
one_simulation = np.random.choice(coin, 100)
total_heads_one_simulation = ...
result = ...
print(result)
```


```{python q6-solution, message = FALSE, warning = FALSE, echo = FALSE}
coin = ['Heads', 'Tails']
one_simulation = np.random.choice(coin, 100)
total_heads_one_simulation = sum(one_simulation == 'Heads')
result = 45 <= total_heads_one_simulation <= 55
print(result)
```

```{r q6-hint,  message = FALSE, warning = FALSE, echo = FALSE}
While you could use multiple condtions and an & here, try to use the fact that a <= x <= b is a valid way to check if a is in the range a to b in python.
```

```{r q6-code-check, message = TRUE, warning = FALSE}
grade_this_code(
  correct = "That's a lot of heads, maybe!",
)
```

### One Simulation: Repeated Rounds

Now that we know how to do one simulation of our desired result we need to do it many times to get an accurate estimate. This presents a problem though in that so far we haven't addressed how to keep track of our results. One way to do so is by making an array and updating it with the outcome of each round simulation. To do that we'll introduce another numpy method

```
np.append(arr, values, axis)
```

`np.append` takes in an array **arr** and adds the new **values** to the end of a copy of it and stores the combination of the elements from **arr** and **values** in a new array. The axis argument can be useful for appending to matrices which won't be dealing with here.

Use the following code snippet to answer question 7.

```
first_five = np.arange(5)
np.arange(first_five, 6)
```

```{r q7, echo=FALSE}
question("7. What is contained in the array `first_five` after the above two lines of code are run? ",
         answer("`np.array([0, 1, 2, 3, 4, 5, 6])`", correct=FALSE),
         answer("`np.array([0, 1, 2, 3, 4, 6])`", correct=FALSE),
         answer("`np.array([0, 1, 2, 3, 4])`", correct=TRUE),
         answer("`np.array([1, 2, 3, 4, 5, 6])`", correct=FALSE),
         answer("`None` There was an Error", correct=FALSE),
         allow_retry = TRUE,
        post_message = "Congratulations! You have found the 3rd secret word: COPY",
  random_answer_order = TRUE)
```

Now it's time to put it all together and run the simulation. Our simulations will generally take the following form.

```
num_iterations = ... # a large number for the number of iterations
results = ... # an empty array or int set to zero that will be updated with our results
for i in np.arange(num_iterations):
  # do one simulation here. This is often multiple lines of code or a function
  # update results with the value of that one simuulation
# summarize the results
```

8. Fill in the blanks below using all the code you've written so far to run 1000 simulations of whether there are 45 to 55 heads in 100 tosses of a fair coin.

```{python q8, exercise = TRUE, message = FALSE, exercise.setup="setup_py", exercise.eval=FALSE}
coin = ['Heads', 'Tails']
num_iterations = ...
results_array = ...
for i in np.arange(num_iterations):
  one_simulation = ...
  total_heads_one_simulation = ...
  one_result = ...
  ...
print(results_array[0:10])
```


```{python q8-solution, message = FALSE, warning = FALSE, echo = FALSE}
coin = ['Heads', 'Tails']
num_iterations = 1000
results_array = np.array([])
for i in np.arange(num_iterations):
  one_simulation = np.random.choice(coin, 100)
  total_heads_one_simulation = sum(one_simulation == 'Heads')
  one_result = 45 <= total_heads_one_simulation <= 55
  results_array = np.append(results_array, one_result)
print(results_array[0:10])
```

```{r q8-code-check, message = TRUE, warning = FALSE}
grade_this_code(
  correct = "That's a lot of flips!",
)
```

#### One Simulation: Summarizing Results

Once we have all our rounds of simulation complete it's time to use them to summarize the results of our simulation. In this case that means computing the estimate of the probability we initially wanted to know.

9. Fill in the blank below to compute our final estimate of the probability that out of 100 tosses of a coin 45-55 end up heads using our `results_array`.

```{python q9-setup, include=FALSE, exercise.setup='setup_py'}
coin = ['Heads', 'Tails']
num_iterations = 1000
results_array = np.array([])
for i in np.arange(num_iterations):
  one_simulation = np.random.choice(coin, 100)
  total_heads_one_simulation = sum(one_simulation == 'Heads')
  one_result = 45 <= total_heads_one_simulation <= 55
  results_array = np.append(results_array, one_result)
```

```{python q9, exercise = TRUE, message = FALSE}
final_probability = ...
print(final_probability)
```

```{python q9-hint, message = FALSE, warning = FALSE, echo = FALSE}
Your answer should include sum and len to be marked correct but there are multiple approaches
```

```{python q9-solution, message = FALSE, warning = FALSE, echo = FALSE}
final_probability = sum(results_array)/len(results_array)
print(final_probability)
```

```{r q9-code-check, message = TRUE, warning = FALSE}
grade_this_code(
  correct = "72% is pretty good!",
)
```


Your answer should be reasonably close to the true probability of ~72.8%. If you increase the number of iterations and try again you'll see that it will be even closer on average.

:::: {.discussionbox}
::: {.center}
**Discuss with a neighbor (or on Ed):**
:::
1. In this question we used arrays to keep track of our results. How would our code change if we used an int to keep track of our results?
::::


make an example 

do $1 milkshake exercise 

## Making the Best Lineup

take in stats from 2024 season for the Chicago White Sox
simulate different lineup combinations (mention caveats)
